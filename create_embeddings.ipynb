{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Der Code unterhalb braucht nur gensim, kann mit `pip install gensim` installiert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import subprocess\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec trainieren\n",
    "\n",
    "Der Code unterhalb ist nur relevant, wenn du das Modell neu trainieren willst - ein fertiges Modell ist allerdings schon geuploaded. \n",
    "\n",
    "Der Code zum Testen / Anwenden ist weiter unten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when reading file XML/._touchepasamastatue_output.xml\n",
      "Error when reading file XML/._novelumcarcassonne_output.xml\n",
      "Error when reading file XML/._normaux_output.xml\n",
      "Error when reading file XML/._Nemesis2_output.xml\n",
      "Error when reading file XML/._Hélix_output.xml\n",
      "Error when reading file XML/._Mora_output.xml\n",
      "Error when reading file XML/._Destoursetdeslys_output.xml\n",
      "Error when reading file XML/._meduanocta_output.xml\n",
      "Error when reading file XML/._Nemesis_output.xml\n",
      "Error when reading file XML/._braves_output.xml\n",
      "Error when reading file XML/._Alvarium_output.xml\n",
      "Error when reading file XML/._natifs_output.xml\n",
      "Error when reading file XML/._patriaalbiges_output.xml\n",
      "Error when reading file XML/._ClermontNC_output.xml\n",
      "Error when reading file XML/._Furie_output.xml\n",
      "Error when reading file XML/._tenesoun_output.xml\n",
      "Error when reading file XML/._GUD_output.xml\n",
      "Error when reading file XML/._remparts_output.xml\n",
      "Error when reading file XML/._Korser_output.xml\n",
      "Error when reading file XML/._maquis_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa11_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa6_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa3_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa2_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa7_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa5_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa12_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa4_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa10_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa9_output.xml\n",
      "Error when reading file XML/Zentropa/._Zentropa8_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade4_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade3_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade5_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade8_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade9_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade2_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade6_output.xml\n",
      "Error when reading file XML/Iliade/._Iliade7_output.xml\n",
      "Error when reading file XML/La cocarde etudiante/._cocardeetudiante3_output.xml\n",
      "Error when reading file XML/La cocarde etudiante/._Cocardeetudiante_output.xml\n",
      "Error when reading file XML/La cocarde etudiante/._cocardeetudiante2_output.xml\n",
      "Error when reading file XML/Academia Christiana/._AcademiaC2_output.xml\n",
      "Error when reading file XML/Academia Christiana/._AcademiaC_output.xml\n",
      "Error when reading file XML/Temeraires/._temeraires_output.xml\n",
      "Error when reading file XML/Temeraires/._temeraires2_output.xml\n"
     ]
    }
   ],
   "source": [
    "def cleanup(text:str, re_cleanup:bool, lowercase:bool)->str: \n",
    "    if lowercase: \n",
    "            text = text.lower()\n",
    "    if re_cleanup: \n",
    "        # Replace all punctuation chars with a single whitespace, keep only normal words and digits\n",
    "        text = re.sub(r\"[^\\w\\n\\d']+\", ' ', text)\n",
    "        text = re.sub(r\"^\\s+|\\s+(?=\\n)\", '', text, flags=re.MULTILINE) # Delete leading/trailing whitespaces\n",
    "    text = re.sub(r'[^(\\n|\\S)]+', ' ', text) # Clean up: spaces (except newlines) to single space\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_text_from_xml(file_path):\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Ensure the XML has the expected format (root is <body>)\n",
    "        if root.tag != 'body':\n",
    "            return []\n",
    "\n",
    "        # Extract text content from all <text> elements\n",
    "        text_elements = root.findall('.//text')\n",
    "        texts = [cleanup(elem.text, re_cleanup=True, lowercase=True) for elem in text_elements if elem.text]\n",
    "        return texts\n",
    "    except Exception as e:\n",
    "        print(f\"Error when reading file {file_path}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    all_texts = []\n",
    "\n",
    "    # Walk through all files and subdirectories\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Check if the file is an .xml file\n",
    "            if file.endswith('.xml'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Extract text from the XML file\n",
    "                extracted_texts = extract_text_from_xml(file_path)\n",
    "                all_texts.extend(extracted_texts)\n",
    "\n",
    "    return all_texts\n",
    "\n",
    "# Specify the folder to process\n",
    "folder_path = 'XML'\n",
    "\n",
    "# Process the folder and print the results\n",
    "all_extracted_texts = process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_corpus.txt\", 'w') as fw: \n",
    "    fw.writelines('\\n'.join(all_extracted_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model = FastText(\n",
    "    corpus_file=\"training_corpus.txt\",\n",
    "    vector_size=100,  # Dimensionality of the word embeddings\n",
    "    window=5,         # Max distance between current and predicted word\n",
    "    min_count=5,      # Ignores all words with total frequency < 3\n",
    "    workers=4,        # Number of threads to run in parallel\n",
    "    epochs=5,          # Number of training epochs\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "# 4) Save the trained model for later use\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `model` is your trained Word2Vec model\n",
    "vocabulary = model.wv.key_to_index\n",
    "\n",
    "# Print the vocabulary (all words)\n",
    "with open(\"vocabulary.txt\", 'w') as fw: \n",
    "    fw.writelines('\\n'.join(list(vocabulary.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell anwenden\n",
    "\n",
    "Wenn in fastText-Modell verwendet wird (ist beim aktuellen word2vec-Modell und dem zugehörigen Code oberhalb der Fall), können beliebige Sequenzen und Wörter getestet werden, unabhängig davon, ob diese in den Trainingsdaten waren. In diesem Fall wird die Eingabe in einzelne, kleinere Buchstabenfolgen zerlegt, die sich in den Trainingsdaten finden. Trotzdem ist das Ergebnis auf Wörtern aus dem Vokabular (kann mit dem Code direkt oberhalb in eine Datei geschrieben werden) vermutlich ab besten. \n",
    "\n",
    "Wenn ein normales Word2Vec-Modell verwendet wird (nicht empfohlen, schlechtere Ergebnisse), können nur Wörter aus dem Vokabular eingegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = FastText.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"qu'aujourd'hui\", 0.960066556930542), (\"d'aujourd'hui\", 0.955970048904419), ('aujourd', 0.816941499710083), ('hui', 0.7796117663383484), ('jourdan', 0.7659460306167603), ('jourdain', 0.7533005475997925), ('résonne', 0.7487667202949524), (\"d'autrefois\", 0.7469144463539124), ('launedujour', 0.745730459690094), ('toujours', 0.7379209399223328), ('béhourd', 0.7367293238639832), ('lourd', 0.7348629832267761), ('séjours', 0.7308028340339661), ('encourue', 0.7272129654884338), ('séjour', 0.7234699726104736), (\"d'habitude\", 0.7185230255126953), (\"l'habitude\", 0.7172859311103821), ('cauchemardesque', 0.7167842388153076), ('beaujolais', 0.7124072313308716), ('demain', 0.7122790813446045)]\n"
     ]
    }
   ],
   "source": [
    "# Find nearest neighbours for single word\n",
    "\n",
    "similar_words = model.wv.most_similar(\"aujourd'hui\", topn=20)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27673393\n"
     ]
    }
   ],
   "source": [
    "# Check similarity between two words\n",
    "similarity = model.wv.similarity(\"aujourd'hui\", \"\")\n",
    "print(similarity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
